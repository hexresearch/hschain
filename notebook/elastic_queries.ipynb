{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib nbagg\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "##\n",
    "import json\n",
    "import re\n",
    "##\n",
    "import numpy           as np\n",
    "import pandas          as pd\n",
    "import statsmodels.api as sm\n",
    "##\n",
    "from elasticsearch     import Elasticsearch, helpers\n",
    "from elasticsearch_dsl import Search, A, Q\n",
    "\n",
    "##\n",
    "import thundermint.plot  as plot\n",
    "import thundermint.splot as splot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"credentials.json\") as f:\n",
    "    credentials = json.load(f)\n",
    "es = Elasticsearch(\"%s:%s@elastic.hxr.team\" % (credentials['login'], credentials['password']), \n",
    "                   port=443, \n",
    "                   use_ssl=True,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global parameters for search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 'xenochain-2018-11-26'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Primitive filters\n",
    "\n",
    "def flt_host(host) :\n",
    "    \"filter by host\"\n",
    "    return lambda s : s.filter('term', host=host)\n",
    "def flt_cluster(cluster) :\n",
    "    \"filter by cluster\"\n",
    "    return lambda s : s.filter('term', env=cluster)\n",
    "def flt_severity(sev) :\n",
    "    \"Filter by severity\"\n",
    "    return lambda s : s.filter('term',  sev=sev)\n",
    "def flt_namespace(ns) :\n",
    "    \"Filter on namespace\"\n",
    "    return lambda s : s.filter('term',  ns=ns)\n",
    "def flt_msg(q, msg):\n",
    "    \"Filter on log message\"\n",
    "    return lambda s : s.filter(q, msg=msg)\n",
    "\n",
    "flt_consensus = flt_namespace('consensus')\n",
    "flt_mempool   = flt_namespace('mempool')\n",
    "flt_net       = flt_namespace('net')\n",
    "\n",
    "def flt_time(start, delta):\n",
    "    \"Filter time range\"\n",
    "    (h1,m1) = start\n",
    "    (dh,dm) = delta\n",
    "    h2 = h1 + dh + (m1+dm) // 60\n",
    "    m2 = (m1+dm) % 60   \n",
    "    r  = re.match(\"^.*-(\\d+-\\d+-\\d+)\", index)\n",
    "    t1 = \"%sT%02i:%02i:00Z\" % (r.group(1), h1, m1)\n",
    "    t2 = \"%sT%02i:%02i:00Z\" % (r.group(1), h2, m2)\n",
    "    return lambda s : s.filter('range', at ={\"gte\":t1, \"lt\":t2})\n",
    "\n",
    "def make_seatch(cluster, filters) :\n",
    "    \"Create Search object from filters\"\n",
    "    s = Search(using=es, index=index)\n",
    "    for f in filters:\n",
    "        s = f(s)\n",
    "    return s\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Postprocessing\n",
    "\n",
    "def postprocess_entries(s) :\n",
    "    r       = pd.DataFrame.from_records([x.to_dict() for x in s.scan()],\n",
    "                                        columns=['at','host','data','msg'])\n",
    "    r['at'] = pd.to_datetime(r['at'])\n",
    "    r       = r.sort_values('at')\n",
    "    return r\n",
    "\n",
    "def postprocess_mempool(r):\n",
    "    r['size']      = r['data'].apply(lambda x: x['size'])\n",
    "    r['filtered']  = r['data'].apply(lambda x: x['filtered'])\n",
    "    r['added']     = r['data'].apply(lambda x: x['added'])\n",
    "    r['discarded'] = r['data'].apply(lambda x: x['discarded'])\n",
    "    r = r.drop('data', axis=1)\n",
    "    return r\n",
    "\n",
    "def split_on_host(df):\n",
    "    return {k : d.reset_index(drop=True) for k,d in df.groupby('host')}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Queries\n",
    "\n",
    "def q_agg_uniq(cluster, filters, field):\n",
    "    \"Aggregate by unique field\"\n",
    "    s = make_seatch(cluster, filters)\n",
    "    s.aggs.bucket('unique_ids', A('terms', field=field))\n",
    "    return s[0:0].execute().aggregations.unique_ids.buckets\n",
    "\n",
    "def q_scan(cluster, filters, host=None, source=['at','msg','data','host'], postprocess=[]):\n",
    "    \"Fetch data from elastic\"\n",
    "    s = make_seatch(cluster, filters).source(source)\n",
    "    s = flt_cluster(cluster)(s)\n",
    "    if host is not None:\n",
    "        s = flt_host(host)(s)\n",
    "    r = postprocess_entries(s)\n",
    "    for f in postprocess:\n",
    "        r = f(r)\n",
    "    if host is None:\n",
    "        r = split_on_host(r)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restarts information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_restarts():\n",
    "    r = q_scan('atum', [ flt_msg(\"match\", \"Starting consensus engine\"),\n",
    "                         flt_namespace(\"consensus\"),\n",
    "                       ])\n",
    "    for (k,v) in r.items() : \n",
    "        print( k)\n",
    "        display( v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logsC = q_scan('atum', [flt_namespace('consensus'),\n",
    "                        flt_time((3,15), (0,25))])\n",
    "logsM = q_scan('atum', [flt_namespace('mempool'),\n",
    "                        flt_time((3,15), (0,25))],\n",
    "                postprocess=[postprocess_mempool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_commit_time(logsC)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_n_tx_in_block(logsC)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_mempool_size([x for x in logsM.values()])\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splot.splot(logsC, w=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rounds vs time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_round(df) :\n",
    "    \"Extract round information from data frame\"\n",
    "    df = df[df['msg'] == 'Entering prevote'].reset_index(drop=True)\n",
    "    df['H'] = df['data'].apply(lambda x: x['H'])\n",
    "    df['R'] = df['data'].apply(lambda x: x['R'])\n",
    "    return df.drop(['data', 'host'], axis=1)\n",
    "\n",
    "def extract_commit(df) :\n",
    "    \"Extract commit information from data frame\"\n",
    "    df = df[df['msg'] == 'Actual commit'].reset_index(drop=True)\n",
    "    df['H'] = df['data'].apply(lambda x: x['H'])\n",
    "    return df.drop(['data', 'host'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = { k:extract_round(v) for k,v in logsC.items()}\n",
    "r.pop('xenogate1')\n",
    "r.pop('xenochain1')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.grid()\n",
    "for k,v in r.items():\n",
    "    plt.plot(v['at'], v['R'], lw=0.5, marker='x', markersize=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
