{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib nbagg\n",
    "import IPython.display\n",
    "import os\n",
    "# ----\n",
    "import json\n",
    "import tempfile\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "# ----\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for importing JSON logs into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(rows, t0=None) :\n",
    "    pd1       = pd.DataFrame.from_records(rows, columns=['at','msg'])\n",
    "    pd1['at'] = pd.to_datetime(pd1['at'])\n",
    "    if t0 is not None:\n",
    "        pd1['dt'] = (pd1['at'] - t0).astype('timedelta64[ms]')\n",
    "    pd2       = pd.DataFrame([l['data'] for l in rows])\n",
    "    return pd.concat([pd1, pd2], axis=1)    \n",
    "    \n",
    "def load_log(fname) :\n",
    "    \"Load JSON log data as list of dictionaries\"\n",
    "    with open(fname) as f :\n",
    "        return [ json.loads(s) for s in f.readlines()]\n",
    "\n",
    "def decode_log(rows) :\n",
    "    \"Load JSON logs for mempool\"\n",
    "    t0 = pd.to_datetime(rows[0]['at'])\n",
    "    rMempool = make_df([l for l in rows if l['ns'] == ['TM','mempool']    ], t0)\n",
    "    rCmtD    = make_df([l for l in rows if l['msg'] == 'Decision to commit'], t0)\n",
    "    rCmtA    = make_df([l for l in rows if l['msg'] == 'Actual commit'     ], t0)\n",
    "    rGsp     = make_df([l for l in rows if l['msg'] == 'Gossip stats'], t0)\n",
    "    return {'after'  : rMempool[rMempool['msg'] == 'Mempool after filtering'].reset_index(),\n",
    "            'before' : rMempool[rMempool['msg'] == 'Mempool before filtering'].reset_index(),\n",
    "            'commit' : pd.DataFrame({'t1':rCmtD['at'],\n",
    "                                     't2':rCmtA['at'],\n",
    "                                     'dt1' : rCmtD['dt'],\n",
    "                                     'dt2' : rCmtA['dt'],\n",
    "                                     'Ntx':rCmtA['Ntx']\n",
    "                                    },\n",
    "                                    index=rCmtD['H']).dropna(),\n",
    "            'gossip' : rGsp\n",
    "           }\n",
    "\n",
    "def read_one_trace(rows, i) :\n",
    "    \"Generate trace for single trace output\"\n",
    "    msgC  = 'Entering new height ----------------'\n",
    "    # Commit trace\n",
    "    rowsC = [l for l in rows if l['msg'] == msgC]\n",
    "    dfC         = make_df(rowsC)\n",
    "    dfC['node'] = i\n",
    "    # Steps trace\n",
    "    rowsS       = [l for l in rows if l['msg'].startswith('Entering') ]\n",
    "#                                  and l['msg'] != 'Entering new height ----------------']\n",
    "    dfS         = make_df(rowsS)\n",
    "    dfS['node'] = 1000 + i\n",
    "    dfS         = dfS.fillna(value={'reason':''})\n",
    "    # Merge traces\n",
    "    dfC = pd.DataFrame(data={'at':dfC['at'], 'node':dfC['node'], 'msg':dfC['H'] % 2})\n",
    "    dfS = pd.DataFrame(data={'at':dfS['at'], 'node':dfS['node'], 'msg':dfS['msg']+' '+dfS['reason']})\n",
    "    return pd.concat([dfC,dfS]).sort_values(by='at').reset_index()\n",
    "\n",
    "def read_trace(logs) :\n",
    "    \"Generate traces for all logs\"\n",
    "    return pd.concat([read_one_trace(l,i) for i,l in enumerate(logs)]).reset_index()\n",
    "\n",
    "def splot(trace, w=1900) :\n",
    "    with tempfile.NamedTemporaryFile(mode='w', suffix='.trace') as f :\n",
    "        for i in [0,1,2,3] :\n",
    "            print( \"%s <NODE%i XXX\" % (trace['at'][0], i), file=f.file)\n",
    "            print( \"%s <NODE%i XXX\" % (trace['at'][0], 1000+i), file=f.file)\n",
    "        for _,q in trace.iterrows() :\n",
    "            print( \"%s >NODE%i %s\" % (q['at'], q['node'], q['msg'] ), file=f.file)\n",
    "        with tempfile.NamedTemporaryFile(suffix='.png') as out :\n",
    "            subprocess.run([\"splot\", \"-w\", str(w), \"-h\", str(4*2*30), \"-bh 20\", \"-if\", f.name, \"-o\", out.name],\n",
    "                           check=True)\n",
    "            return IPython.display.Image(out.name, unconfined=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = ['../ser2/logs/node-1',\n",
    "        '../ser2/logs/node-2',\n",
    "        '../ser2/logs/node-3',\n",
    "        '../ser2/logs/node-4',\n",
    "       ]\n",
    "logData = [load_log(n)   for n in logs]\n",
    "dfs     = [decode_log(n) for n in logData]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blocks plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun():\n",
    "    plt.figure()\n",
    "    plt.grid()\n",
    "    plt.title(\"Block size\")\n",
    "    plt.xlabel(\"Height\")\n",
    "    plt.ylabel(\"N of transactions\")\n",
    "    tot = np.sum(dfs[0]['commit']['Ntx'])\n",
    "    avg = np.average(dfs[0]['commit']['Ntx'])\n",
    "    for df in dfs :\n",
    "        plt.plot(df['commit'].index, df['commit']['Ntx'])\n",
    "    plt.axhline(y=avg, color='k')\n",
    "    print( \"Total transactions commited: \", tot )\n",
    "    print( \"Transactions per block:      \", avg )\n",
    "fun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun():\n",
    "    # Do linear fit of commit times which are averaged over all nodes\n",
    "    n  = np.min([df['commit']['dt2'].shape[0] for df in dfs])\n",
    "    hs = np.asarray( dfs[0]['commit'].index )[0:n]\n",
    "    ts = np.average( [df['commit']['dt2'][0:n] for df in dfs], axis=0 )\n",
    "    r = sm.OLS(ts, sm.add_constant(hs), missing='drop').fit()\n",
    "    #\n",
    "    fig = plt.figure()\n",
    "    plt.grid()\n",
    "    plt.title('Commit time')\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('Height')\n",
    "    plt.plot(hs*r.params[1] + r.params[0], hs, color='grey', linewidth=0.5)\n",
    "    for df in dfs :\n",
    "        plt.plot(df['commit']['dt2'] , df['commit'].index, '+')\n",
    "    print(\"Time for commit of singe block %.3f s\" % float(r.params[1] / 1000))\n",
    "    return fig\n",
    "\n",
    "fun().savefig('plot.png')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mempool plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun():\n",
    "    plt.figure()\n",
    "    plt.grid()\n",
    "    plt.title(\"Number of transaction added to mempool\")\n",
    "    for df in dfs :\n",
    "        plt.plot(df['after']['at'], df['after']['added'], '+')\n",
    "        plt.plot(df['after']['at'], df['after']['discarded'], 'x')\n",
    "#        plt.plot(df['after']['at'], df['after']['filtered'], '.')\n",
    "fun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun():\n",
    "    plt.figure()\n",
    "    plt.grid()\n",
    "    plt.title(\"Mempool size\")\n",
    "    for df in dfs :\n",
    "        plt.plot(df['after']['size'], '+-.')\n",
    "fun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.grid()\n",
    "plt.title(\"Number of transactions filtered after commit\")\n",
    "for df in dfs :\n",
    "    plt.plot(df['after']['filtered'] - df['before']['filtered'], '+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(key):\n",
    "    for df in dfs :\n",
    "        plt.figure()\n",
    "        plt.grid()\n",
    "        plt.title(\"Cumulative number of transactions\")\n",
    "        plt.plot(df['gossip']['at'], df['gossip']['Rx'+key], label='Rx' )\n",
    "        plt.plot(df['gossip']['at'], df['gossip']['Tx'+key], label='Tx' )\n",
    "        plt.legend()\n",
    "fun('Tx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splot(read_trace(logData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
